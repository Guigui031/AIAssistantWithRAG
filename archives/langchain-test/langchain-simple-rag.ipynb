{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce93fdb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\guill\\GitHub\\AIAssistantWithRAG\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatGroq(model_name=\"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9818f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guill\\AppData\\Local\\Temp\\ipykernel_16900\\3590037574.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "452872a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"example_collection\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_langchain_db\",  # Where to save data locally, remove if not necessary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3843a19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "# Load and chunk contents of the blog\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Index chunks\n",
    "_ = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "# Define prompt for question-answering\n",
    "# N.B. for non-US LangSmith endpoints, you may need to specify\n",
    "# api_url=\"https://api.smith.langchain.com\" in hub.pull.\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "# Compile application and test\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e67be94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task decomposition is the process of breaking down a complex task into smaller, more manageable steps or subgoals. This can be achieved through various methods, including using large language models (LLMs) with simple prompting or task-specific instructions. Task decomposition helps to transform big tasks into multiple simpler tasks, making it easier to plan and execute the overall task.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"What is Task Decomposition?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ed12762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [Document(id='864caead-5235-474f-8f10-d0945d19ee75', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#'), Document(id='18027943-d5fb-434a-9c29-6e7edd3cc8f6', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Component One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.'), Document(id='6e9582f2-227e-458b-a40f-3b42ab8afb30', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.'), Document(id='627978ed-ca8a-469d-a5f7-b69c5be1617f', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\n\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:')]\n",
      "\n",
      "\n",
      "Answer: Task decomposition is the process of breaking down a complex task into smaller, more manageable steps or subgoals. This can be achieved through various methods, including simple prompting, task-specific instructions, or using external tools like classical planners. Task decomposition helps to transform big tasks into multiple smaller tasks, making it easier to plan and execute the overall task.\n"
     ]
    }
   ],
   "source": [
    "result = graph.invoke({\"question\": \"What is Task Decomposition?\"})\n",
    "\n",
    "print(f\"Context: {result['context']}\\n\\n\")\n",
    "print(f\"Answer: {result['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18f8d3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'retrieve': {'context': [Document(id='864caead-5235-474f-8f10-d0945d19ee75', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#'), Document(id='18027943-d5fb-434a-9c29-6e7edd3cc8f6', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Component One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.'), Document(id='6e9582f2-227e-458b-a40f-3b42ab8afb30', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.'), Document(id='627978ed-ca8a-469d-a5f7-b69c5be1617f', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\n\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:')]}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'generate': {'answer': 'Task decomposition is the process of breaking down a complex task into smaller, more manageable steps or subgoals. This can be done using various approaches, including simple prompting, task-specific instructions, or human inputs, as well as more complex methods like relying on an external classical planner. Task decomposition is essential for planning and problem-solving, as it allows agents to understand the individual steps involved in a task and plan ahead.'}}\n",
      "\n",
      "----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in graph.stream(\n",
    "    {\"question\": \"What is Task Decomposition?\"}, stream_mode=\"updates\"\n",
    "):\n",
    "    print(f\"{step}\\n\\n----------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70b68250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Task| decomposition| is| the| process| of| breaking| down| a| complex| task| into| smaller|,| more| manageable| steps| or| sub|goals|.| This| can| be| achieved| through| various| methods|,| including| using| large| language| models| (|LL|Ms|)| with| simple| prompting| or| task|-specific| instructions|.| Task| decomposition| helps| to| make| complex| tasks| more| manageable| and| allows| for| more| effective| planning| and| problem|-solving|.||"
     ]
    }
   ],
   "source": [
    "for message, metadata in graph.stream(\n",
    "    {\"question\": \"What is Task Decomposition?\"}, stream_mode=\"messages\"\n",
    "):\n",
    "    print(message.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b6a5890",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Use three sentences maximum and keep the answer as concise as possible.\n",
    "Always say \"thanks for asking!\" at the end of the answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "custom_rag_prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cbec34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import Annotated, List, TypedDict\n",
    "\n",
    "# Load and chunk contents of the blog\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "\n",
    "# Update metadata (illustration purposes)\n",
    "total_documents = len(all_splits)\n",
    "third = total_documents // 3\n",
    "\n",
    "for i, document in enumerate(all_splits):\n",
    "    if i < third:\n",
    "        document.metadata[\"section\"] = \"beginning\"\n",
    "    elif i < 2 * third:\n",
    "        document.metadata[\"section\"] = \"middle\"\n",
    "    else:\n",
    "        document.metadata[\"section\"] = \"end\"\n",
    "\n",
    "\n",
    "# Index chunks\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "_ = vector_store.add_documents(all_splits)\n",
    "\n",
    "\n",
    "# Define schema for search\n",
    "class Search(TypedDict):\n",
    "    \"\"\"Search query.\"\"\"\n",
    "\n",
    "    query: Annotated[str, ..., \"Search query to run.\"]\n",
    "    section: Annotated[\n",
    "        Literal[\"beginning\", \"middle\", \"end\"],\n",
    "        ...,\n",
    "        \"Section to query.\",\n",
    "    ]\n",
    "\n",
    "# Define prompt for question-answering\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    query: Search\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "def analyze_query(state: State):\n",
    "    structured_llm = llm.with_structured_output(Search)\n",
    "    query = structured_llm.invoke(state[\"question\"])\n",
    "    return {\"query\": query}\n",
    "\n",
    "\n",
    "def retrieve(state: State):\n",
    "    query = state[\"query\"]\n",
    "    retrieved_docs = vector_store.similarity_search(\n",
    "        query[\"query\"],\n",
    "        filter=lambda doc: doc.metadata.get(\"section\") == query[\"section\"],\n",
    "    )\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([analyze_query, retrieve, generate])\n",
    "graph_builder.add_edge(START, \"analyze_query\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88e2dcf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6098ec64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'analyze_query': {'query': {'query': 'Task Decomposition', 'section': 'end'}}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'retrieve': {'context': [Document(id='a99b05d6-5577-4f6a-9514-fefb4da6b031', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'section': 'end'}, page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.'), Document(id='06ee70de-939d-42aa-b94c-571f07047738', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'section': 'end'}, page_content='Here are a sample conversation for task clarification sent to OpenAI ChatCompletion endpoint used by GPT-Engineer. The user inputs are wrapped in {{user input text}}.\\n[\\n  {\\n    \"role\": \"system\",\\n    \"content\": \"You will read instructions and not carry them out, only seek to clarify them.\\\\nSpecifically you will first summarise a list of super short bullets of areas that need clarification.\\\\nThen you will pick one clarifying question, and wait for an answer from the user.\\\\n\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"We are writing {{a Super Mario game in python. MVC components split in separate files. Keyboard control.}}\\\\n\"\\n  },\\n  {\\n    \"role\": \"assistant\",'), Document(id='053f3efe-d553-440d-8584-8cdf5ed123a1', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'section': 'end'}, page_content='[6] Google Blog. “Announcing ScaNN: Efficient Vector Similarity Search” July 28, 2020.\\n[7] https://chat.openai.com/share/46ff149e-a4c7-4dd7-a800-fc4a642ea389\\n[8] Shinn & Labash. “Reflexion: an autonomous agent with dynamic memory and self-reflection” arXiv preprint arXiv:2303.11366 (2023).\\n[9] Laskin et al. “In-context Reinforcement Learning with Algorithm Distillation” ICLR 2023.\\n[10] Karpas et al. “MRKL Systems A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning.” arXiv preprint arXiv:2205.00445 (2022).\\n[11] Nakano et al. “Webgpt: Browser-assisted question-answering with human feedback.” arXiv preprint arXiv:2112.09332 (2021).\\n[12] Parisi et al. “TALM: Tool Augmented Language Models”\\n[13] Schick et al. “Toolformer: Language Models Can Teach Themselves to Use Tools.” arXiv preprint arXiv:2302.04761 (2023).\\n[14] Weaviate Blog. Why is Vector Search so fast? Sep 13, 2022.'), Document(id='53e7f7fb-05bb-44a8-8492-fb6423073b70', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'section': 'end'}, page_content='Or\\n@article{weng2023agent,\\n  title   = \"LLM-powered Autonomous Agents\",\\n  author  = \"Weng, Lilian\",\\n  journal = \"lilianweng.github.io\",\\n  year    = \"2023\",\\n  month   = \"Jun\",\\n  url     = \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\\n}\\nReferences#\\n[1] Wei et al. “Chain of thought prompting elicits reasoning in large language models.” NeurIPS 2022\\n[2] Yao et al. “Tree of Thoughts: Dliberate Problem Solving with Large Language Models.” arXiv preprint arXiv:2305.10601 (2023).\\n[3] Liu et al. “Chain of Hindsight Aligns Language Models with Feedback\\n“ arXiv preprint arXiv:2302.02676 (2023).\\n[4] Liu et al. “LLM+P: Empowering Large Language Models with Optimal Planning Proficiency” arXiv preprint arXiv:2304.11477 (2023).\\n[5] Yao et al. “ReAct: Synergizing reasoning and acting in language models.” ICLR 2023.\\n[6] Google Blog. “Announcing ScaNN: Efficient Vector Similarity Search” July 28, 2020.\\n[7] https://chat.openai.com/share/46ff149e-a4c7-4dd7-a800-fc4a642ea389')]}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'generate': {'answer': 'The end of the post does not specifically mention Task Decomposition. However, it is mentioned earlier in the context that challenges in long-term planning and task decomposition remain, with LLMs struggling to adjust plans when faced with unexpected errors. This suggests that task decomposition is a challenging area for LLMs.'}}\n",
      "\n",
      "----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in graph.stream(\n",
    "    {\"question\": \"What does the end of the post say about Task Decomposition?\"},\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    print(f\"{step}\\n\\n----------------\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
